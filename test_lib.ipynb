{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mini_scikit_learn in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mini_scikit_learn) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 24.0\n",
      "[notice] To update, run: c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install mini_scikit_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "(359, 10)\n",
      "(359, 64)\n",
      "Accuracy: 0.958217270194986\n"
     ]
    }
   ],
   "source": [
    "from mini_scikit_learn import RandomForestClassifier\n",
    "from mini_scikit_learn import transformers\n",
    "from mini_scikit_learn.utils import train_test_split\n",
    "from mini_scikit_learn.transformers import StandardScaler\n",
    "from mini_scikit_learn.transformers import OneHotEncoder\n",
    "from mini_scikit_learn import NeuralNetwork, Layer\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_decision_tree_classifier_iris():\n",
    "    # Load the iris dataset\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "def test_decision_tree_classifier_digits():\n",
    "    digits = load_digits()\n",
    "    X, y = digits.data, digits.target\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "     \n",
    "def test_neural_network_classifier_digits():\n",
    "    digits = load_digits()\n",
    "    X = digits.data\n",
    "    y = digits.target.reshape(-1, 1)\n",
    "    subset_fraction = 0.3\n",
    "    subset_size = int(X.shape[0] * subset_fraction)\n",
    "    indices = np.random.choice(X.shape[0], subset_size, replace=False)\n",
    "    X_subset =X\n",
    "    y_subset =y\n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_subset)\n",
    "    # One-hot encode labels\n",
    "    encoder = OneHotEncoder()\n",
    "    y_encoded = encoder.fit_transform(y_subset).toarray()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "    clf=NeuralNetwork()\n",
    "    clf.add(Layer(64, 64, 'sigmoid'))\n",
    "    clf.add(Layer(64, 10, 'sigmoid'))\n",
    "    clf.fit(X_train, y_train, epochs=500, learning_rate=0.1)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    print(f\"Accuracy of Neural Network: {accuracy}\")\n",
    "\n",
    "test_decision_tree_classifier_iris()\n",
    "test_neural_network_classifier_digits()\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9701492537313433\n",
      "1.0\n",
      "X_meta shape\n",
      "(134, 3)\n",
      "Meta model score\n",
      "1.0\n",
      "Answer shape\n",
      "(44,)\n",
      "Answer\n",
      "[0 0 2 0 1 0 1 2 1 2 1 2 0 1 0 1 1 1 0 1 0 1 1 2 2 2 1 1 1 0 0 1 2 0 0 0 2\n",
      " 2 1 2 0 1 1 1]\n",
      "Accuracy of Stacking Ensembler: 0.9772727272727273\n"
     ]
    }
   ],
   "source": [
    "from mini_scikit_learn import RandomForestClassifier, LogisticRegression, NBClassifier, KNNEstimator\n",
    "from mini_scikit_learn import StackingEnsembler\n",
    "from mini_scikit_learn.utils import train_test_split\n",
    "from mini_scikit_learn import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Load wine dataset\n",
    "wine = load_wine()\n",
    "X, y = wine.data, wine.target\n",
    "rf=RandomForestClassifier()\n",
    "nb=NBClassifier()\n",
    "knn=KNNEstimator(n_neighbors=1)\n",
    "base_models=[rf,nb,knn]\n",
    "meta_model=DecisionTreeClassifier()\n",
    "stacking=StackingEnsembler(base_models, meta_model)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "stacking.fit(X_train, y_train)\n",
    "accuracy = stacking.score(X_test, y_test)\n",
    "print(f\"Accuracy of Stacking Ensembler: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Linear Regression: 0.609873031052925\n",
      "Best Parameters: {'fit_intercept': True, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "#import boston price dataset\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from mini_scikit_learn import RandomForestRegressor, LinearRegression, DecisionTreeRegressor\n",
    "from mini_scikit_learn.utils import train_test_split\n",
    "from mini_scikit_learn.transformers import StandardScaler\n",
    "from mini_scikit_learn.model_selection import GridSearch\n",
    "\n",
    "\n",
    "\n",
    "california_housing = fetch_california_housing()\n",
    "X, y = california_housing.data, california_housing.target\n",
    "\n",
    "rf=LinearRegression()\n",
    "dt=DecisionTreeRegressor()\n",
    "gd=GridSearch(rf, {'fit_intercept': [True, False], n,\"learning_rate\": [0.1, 0.01, 0.001]})\n",
    "gd1=GridSearch(dt, {'max_depth': [10, 20, 30, 40, 50]})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "gd.fit(X_train, y_train)\n",
    "gd1.fit(X_train, y_train)\n",
    "\n",
    "accuracy = gd.get_best_score()\n",
    "accuracy1 = gd1.get_best_score()\n",
    "best_params=gd.get_best_params()\n",
    "\n",
    "print(f\"Accuracy of Linear Regression: {accuracy}\")\n",
    "print(f\"Accuracy of Decision Tree: {accuracy}\")\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
